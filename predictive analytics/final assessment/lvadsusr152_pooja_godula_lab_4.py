# -*- coding: utf-8 -*-
"""LVADSUSR152_POOJA_GODULA_LAB_4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OFIzLadYuqA6D5g5j-nN9DApkO-4BhbP
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

data=pd.read_csv('anomaly_train.csv')

data.columns

data.shape

data.isnull().sum()

data.duplicated().sum()

data.dtypes

data.head()

data['Location'].value_counts()

from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
data['Location']=le.fit_transform(data['Location'])
data['Type']=le.fit_transform(data['Type'])

sns.countplot(x = data['Location'])

data.dtypes

plt.figure(figsize=(16,9))
sns.heatmap(data=data.corr(),annot=True)

from sklearn.model_selection import train_test_split
from sklearn.ensemble import IsolationForest

model_outlier = IsolationForest(contamination=0.1, random_state=42)
outliers = model_outlier.fit_predict(data[['Amount','Type', 'Location']])
data['is_an_outlier'] = outliers

data['is_an_outlier'].value_counts()

features = ['Amount','Type','Location']
X = data[features]
y = data['is_an_outlier']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
model = IsolationForest(n_estimators=100, contamination=0.1, max_features=3, max_samples=10000, random_state=42)
model.fit(X_train)

y_pred = model.predict(X_train)
data["anomaly_score"] = model.decision_function(X)
anomalies = data.loc[data["anomaly_score"] < 0]

data

plt.scatter(data["Location"], data["Type"], label="Not an Anomaly")
plt.scatter(anomalies["Amount"], anomalies["anomaly_score"], color="r", label="Anomaly")
plt.xlabel("Type")
plt.ylabel("Anomaly Score")
plt.title("Scatter plot for Type and Anomaly Score")
plt.legend(loc='lower right')
plt.show()